{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Core Learning Algorithm Clustering and Hidden Markov Models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeFeF8vVJkLDhvO8XJDGgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi221a/FreeCodeCamp_TensorFlow/blob/main/Core_Learning_Algorithm_Clustering_and_Hidden_Markov_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering\n",
        "\n",
        "Now that we've covered regression and classification it's time to talk about clustering data!\n",
        "\n",
        "Clustering is a Machine LEarning technique that involves the grouping of data points. In theory, data points that are in the same group should have similar properties and /or features, while data points in different groups should have highly dissimilar properties and/or features.\n",
        "(https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)\n",
        "\n",
        "Unfortunately there are issues with the current version of TensorFlow and the implementation for KMeans. This means we cannot use KMeans without writting algorithm from scratch. We aren't quite that level yet so we'll just explain thae basics of clusturing for now.\n",
        "\n",
        "## Basic Algorithm for K-Means.\n",
        "\n",
        " * Step 1: Randomly pick K points to place K centroids\n",
        " * Step 2: Assign all of the data points belonging to each centroid by distance. The closest centroid to a point is the one it is assigned to.\n",
        " * Step 3: Averege all of the points belongling to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
        " * Step 4: Reassign every point once again to the closest centroid.\n",
        " * Step 5: Reeat steps 3-4 untill no point changes which centroid it belongs to."
      ],
      "metadata": {
        "id": "6eZCf6rkG3l-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models\n",
        "\n",
        "The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution. Transitions among the states are governed by a set of probabilities called transition probabilities.\n",
        "(http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
        "\n",
        "A hidden markov model works with probabilities to predict future events or states. In this section we will learn how to create a hidden markov model that can predict the weather.\n",
        "\n",
        "This section is based on the following TensorFlow tutorial\n",
        "https://www.tensorflow.org/probability/api_docs/python/tfp.distributions/HiddenMarkovModel\n",
        "\n",
        "##Data\n",
        "\n",
        "Let's start by discussing the type of data we use when we work with a hidden markov model.\n",
        "\n",
        "In the previous sections we worked with large datasets of 100's of different entries. For a markov model we are only interested in probability distributions that have to do with states.\n",
        "\n",
        "We can find these probabilites from large datasets or may already have these values. We'll run through an example in a second that should clear some things up, but let's discuss the components of a morkov model.\n",
        "\n",
        "**States**: In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we donot direcly observe tham.\n",
        "\n",
        "**Observation**: Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following : _ On a hot day Tim has a 80% chance of being happy and 20% chance of being sad_\n",
        "\n",
        "**Transtions**:Each state will have a probability defining the likelyhood of transtitioning to a different state. An example is the following : _a cold day has a 30% chance of being followed by a hot day and 70% chance of being followed by another cold day._\n",
        "\n",
        "To create a hidden markov model we need.\n",
        "\n",
        "  * Atates\n",
        "  * Observation Distribution\n",
        "  * Transistion Distribution\n",
        "\n",
        "For our purpose we will assume we already have this information available as we attempt to predict the weather on a given day.\n",
        "\n"
      ],
      "metadata": {
        "id": "T4uir3G6oiQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Setup"
      ],
      "metadata": {
        "id": "R1hqIFVCt6Jl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cNf17kzeGsDL"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp \n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "-zEQjcfpuC0U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weather Model\n",
        "\n",
        "Taken directly from the TensorFlow documentation\n",
        "\n",
        "(https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel)\n",
        "\n",
        "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
        "\n",
        "  1. Cold days are encoded aby a 0 and hot days are encoded by a 1.\n",
        "  2. The first day in our sequence has an 80% chance of being cold.\n",
        "  3. A cold day has 30% chance of being followed by a hot day.\n",
        "  4. Ahot dy has a 20% chance of being followed by a cold day/\n",
        "  5. On each day the temperature is normally distributed with mean and sd 0 and 5 on a cold day and mean and sd 15 and 10 on a hot day.\n",
        "\n"
      ],
      "metadata": {
        "id": "RX4lGYqGvJQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfd = tfp.distributions # making a shortcut for later on \n",
        "initial_distribution = tfd.Categorical(probs=[0.8, 0.2]) #Refer to point 2 above\n",
        "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3], \n",
        "                                                 [0.2, 0.8]])  #refer to points 3 and 4\n",
        "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) #refer to point 5 above\n",
        "\n",
        "# the lo argument represents the mean and the scale is the standard deviation\n",
        "                                            "
      ],
      "metadata": {
        "id": "kUsD5mhRC5l8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've now created distribution variables to model our system and it's time to create the hidden markov model."
      ],
      "metadata": {
        "id": "1jpH860OEryP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tfd.HiddenMarkovModel(initial_distribution=initial_distribution,\n",
        "                              transition_distribution=transition_distribution,\n",
        "                              observation_distribution=observation_distribution,\n",
        "                              num_steps=7)"
      ],
      "metadata": {
        "id": "I6iED7S3E9HE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numbner of steps represents the number of days that we would like to predict information for. In this case we've chosen 7, an entire week.\n",
        "\n",
        "To get the expected temperatures on each day we can do the folloewing."
      ],
      "metadata": {
        "id": "2z7IodclFy_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = model.mean()\n",
        "\n",
        "# due to the way TensorFlow workd on a lower level we need to evaluate part of the graph\n",
        "# from within a session to see the value of this tensor\n",
        "\n",
        "# in the new version of tensor we need to use tf.cmpat.v1.Session() rather than just tf.Session()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  print(mean.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTQk-KfMGZqb",
        "outputId": "cc45d61f-590a-4879-b5f0-43eeac9e24e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.9999998 5.9999995 7.4999995 8.25      8.625001  8.812501  8.90625  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "So that's it for the core learning algorithms in TensorFlow."
      ],
      "metadata": {
        "id": "wNMu8LyPHlVZ"
      }
    }
  ]
}